{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qSfAPWjmqsqt"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn import metrics, svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5mTeXyWqh_X"
      },
      "source": [
        "### Baseline SVM Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb-kEWwwK9Iu"
      },
      "source": [
        "Load and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83ZLy_5rFFoE"
      },
      "outputs": [],
      "source": [
        "# load and prepare data\n",
        "def load_data():\n",
        "\n",
        "  # load dataset\n",
        "  (train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
        "\n",
        "  # convert from pixel data to floats and normalize from 0-1\n",
        "  train_data_norm = train_data.astype('float32') / 255.0\n",
        "  test_data_norm = test_data.astype('float32') / 255.0\n",
        "\n",
        "  # flatten pixel data to 2d\n",
        "  train_data_flatten = train_data_norm.reshape(50000,-1)\n",
        "  test_data_flatten = test_data_norm.reshape(10000,-1)\n",
        "\n",
        "  # reduce label data to 1d array\n",
        "  train_labels_1d = train_labels.reshape(-1,)\n",
        "  test_labels_1d = test_labels.reshape(-1,)\n",
        "\n",
        "  # choose a subset of the training dataset for training the optimal model\n",
        "  #val_data = train_data_flatten[41500:, :]\n",
        "  #val_labels = train_labels_1d[41500:]\n",
        "\n",
        "  train_data =  train_data_flatten[:, :]\n",
        "  train_labels = train_labels_1d[:]\n",
        "\n",
        "  test_data =test_data_flatten[:, :]\n",
        "  test_labels = test_labels_1d[:]\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "# call function\n",
        "train_data, train_labels, test_data, test_labels = load_data()\n",
        "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huyB2R5gxlWn"
      },
      "source": [
        "Parameter search for optimal SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hu7efNvxQN0"
      },
      "outputs": [],
      "source": [
        "# indicate number of training observations to perform grid serach on\n",
        "n = 2000\n",
        "\n",
        "param_grid = {'C': [10], 'gamma': [0.1], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
        "\n",
        "svm_grid = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=2)\n",
        "svm_grid.fit(train_data[:n,:], train_labels[:n])\n",
        "\n",
        "svm_clf = svm_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd6IiQ7pzK_y"
      },
      "outputs": [],
      "source": [
        "print(svm_grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO9Ylh328eWH"
      },
      "source": [
        "train simple SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBDM9k_rzZTk"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "svm_clf = svm.SVC(C=10, gamma=0.1, kernel='poly')\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# fit classifier\n",
        "svm_clf.fit(train_data, train_labels)\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Training Time (Basic SVM): ', stop-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heS0gyCo8igX"
      },
      "source": [
        "test simple SVM on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y89AxqJNyAWY"
      },
      "outputs": [],
      "source": [
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# make predictions\n",
        "predicted = svm_clf.predict(test_data)\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Infrence Time (Basic SVM): ', stop-start)\n",
        "\n",
        "# print a classification report (built in to sklearn)\n",
        "svm_metrics = metrics.classification_report(test_labels, predicted, digits=5, target_names=classesName)\n",
        "print(\"Classification report: \\n\", svm_metrics)\n",
        "\n",
        "# display confusion matrix\n",
        "cm_svm = confusion_matrix(test_labels, predicted)\n",
        "print(f\"Confusion matrix:\\n{cm_svm}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfAynPfigE02"
      },
      "source": [
        "# Open CV Saliency Maps\n",
        "\n",
        "open CV saliency tutorial: https://www.pyimagesearch.com/2018/07/16/opencv-saliency-detection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fcl7dpaJgG9A"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from scipy.signal import convolve2d as conv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XSOWEHPq2y4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7b3941dd-e168-4357-d9dc-2375ad17b4b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# choose a subset of the training dataset for training the optimal model\\nval_data = train_data[41500:, :, :, :]\\nval_labels = train_labels[41500:]\\n\\ntrain_data = train_data[:20000, :, :, :]\\ntrain_labels = train_labels[:20000]\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# load and prepare data\n",
        "def load_data_opencv():\n",
        "\n",
        "  # load dataset\n",
        "  (train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
        "\n",
        "  # convert from pixel data to floats and normalize from 0-1\n",
        "  train_data_norm = train_data.astype('float32') / 255.0\n",
        "  test_data_norm = test_data.astype('float32') / 255.0\n",
        "\n",
        "  # flatten pixel data to 2d\n",
        "  #train_data_flatten = train_data_norm.reshape(50000,-1)\n",
        "  #test_data_flatten = test_data_norm.reshape(10000,-1)\n",
        "\n",
        "  # reduce label data to 1d array\n",
        "  train_labels_1d = train_labels.reshape(-1,)\n",
        "  test_labels_1d = test_labels.reshape(-1,)\n",
        "\n",
        "  return train_data_norm, train_labels_1d, test_data_norm, test_labels_1d\n",
        "\n",
        "# call function\n",
        "train_data, train_labels, test_data, test_labels = load_data_opencv()\n",
        "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "''' this was used for validation\n",
        "# choose a subset of the training dataset for training the optimal model\n",
        "val_data = train_data[41500:, :, :, :]\n",
        "val_labels = train_labels[41500:]\n",
        "\n",
        "train_data = train_data[:20000, :, :, :]\n",
        "train_labels = train_labels[:20000]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkEkNYPK8pL9"
      },
      "source": [
        "Define saliency function using pretrained module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X1gJjaJHgbJi"
      },
      "outputs": [],
      "source": [
        "# generate saliency maps using the OpenCV library\n",
        "def saliency_spectral(image):\n",
        "    saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
        "    (success, saliencyMap) = saliency.computeSaliency(image)\n",
        "    saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
        "    \n",
        "    output = image * saliencyMap.reshape(32, 32, 1)\n",
        "\n",
        "    return saliencyMap, output\n",
        "\n",
        "\n",
        "# function to find nxn subset of data with most saliency\n",
        "def maximum_saliency_region(salMap, n, image):\n",
        "    idx = conv2(salMap, np.ones((n, n), dtype=int), 'same').argmax()\n",
        "    row, col = np.unravel_index(idx, salMap.shape)\n",
        "    offset = n//2\n",
        "\n",
        "    if row < offset:\n",
        "      row = offset\n",
        "    if row > (32-offset):\n",
        "      row = 32-offset\n",
        "    \n",
        "    if col < offset:\n",
        "      col = offset\n",
        "    if col > (32-offset):\n",
        "      col = 32-offset\n",
        "    \n",
        "    row_start = row - offset\n",
        "    row_end = row+offset\n",
        "    col_start = col - offset\n",
        "    col_end = col + offset\n",
        "\n",
        "    return image[row_start:row_end, col_start:col_end, :]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_7JIOkl8qx4"
      },
      "source": [
        "Run Saliency Subset method\n",
        "\n",
        "\n",
        "*   Generate saliency maps per image\n",
        "*   Run the maximum_saliency_region function to crop each image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GRSCGZwgR3p",
        "outputId": "549f9d3e-9c7e-426f-8e7a-03ea0fd9ee25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saliency Map Forward Pass Time:  106.0933062869999\n"
          ]
        }
      ],
      "source": [
        "n=28\n",
        "\n",
        "train_size = 50000\n",
        "\n",
        "saliencyMap = np.zeros((train_size,32,32))\n",
        "saliencyOutput = np.zeros((train_size,32,32,3))\n",
        "subset_image_data = np.zeros((train_size, n, n, 3))\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "for i in range(train_size):\n",
        "  image = train_data[i,:,:,:]\n",
        "  \n",
        "  map, _ = saliency_spectral(image)\n",
        "  saliencyMap[i,:,:] = map\n",
        "  \n",
        "  ''' uncomment to do saliency subset calc'''\n",
        "  # take nxn subset of data with most saliency\n",
        "  subset_image = maximum_saliency_region(map, n, image)\n",
        "  subset_image_data[i, :, :, :] = subset_image\n",
        "  \n",
        "  ''' uncomment to do center subset calc \n",
        "  # take same nxn subset of data for all images to compare\n",
        "  subset_image = image[16-n//2: 16+n//2, 16-n//2: 16+n//2, :]\n",
        "  subset_image_data[i, :, :, :] = subset_image\n",
        "  '''\n",
        "\n",
        "  ''' uncomment to visualize a few images \n",
        "  if i in [4,7,9,20]:\n",
        "  \n",
        "    print(classesName[train_labels[i]])\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "    ax1.imshow(image)\n",
        "    ax2.imshow(map, cmap=\"gray\")\n",
        "    ax3.imshow(subset_image)\n",
        "    plt.show()\n",
        "  \n",
        "  if i==20:\n",
        "    break\n",
        "  '''\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "\n",
        "print('Saliency Map Forward Pass Time: ', stop-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LeH_mDK9IVGj"
      },
      "outputs": [],
      "source": [
        "# reshape saliency maps\n",
        "subset_image_data = subset_image_data.reshape(train_size,-1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-1IPqW30BZq"
      },
      "source": [
        "Train the same baseline SVM on the new saliency subset data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FzuhtR5yn-Q",
        "outputId": "30cbb790-c952-4ce6-c61d-72cdd2be102c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (SVM with saliency maps):  2422.8266793760004\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "svm_clf_sal = SVC(C=10, gamma=0.1, kernel='polynomial')\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# fit classifier\n",
        "svm_clf_sal.fit(subset_image_data, train_labels[:train_size])\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Training Time (SVM with saliency maps): ', stop-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPOxE0kO9-FI"
      },
      "source": [
        "Run Saliency Subset method on the Validaiton Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn2B9tTVlOYm"
      },
      "outputs": [],
      "source": [
        "val_size = 8500\n",
        "\n",
        "saliencyOutput_val = np.zeros((val_size,32,32,3))\n",
        "saliencyMap_val = np.zeros((val_size,32,32))\n",
        "subset_image_data_val = np.zeros((val_size,n,n,3))\n",
        "\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "for i in range(val_size):\n",
        "  image = val_data[i,:,:,:].reshape(32,32,3)\n",
        "  map, _ = saliency_spectral(image)\n",
        "  saliencyMap_val[i,:,:] = map\n",
        "\n",
        "  ''' uncomment to do saliency subset calc\n",
        "  # take nxn subset of data with most saliency\n",
        "  subset_image = maximum_saliency_region(map, n, image)\n",
        "  subset_image_data_val[i, :, :, :] = subset_image\n",
        "  '''\n",
        "  ''' uncomment to do center subset calc  '''\n",
        "  # take same nxn subset of data for all images to compare\n",
        "  subset_image = image[32-n:, 32-n:, :]\n",
        "  subset_image_data_val[i, :, :, :] = subset_image\n",
        "\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Saliency Map Forward Pass Time: ', stop-start)\n",
        "\n",
        "\n",
        "subset_image_data_val = subset_image_data_val.reshape(val_size,-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the SVM with Saliency Subset Feature Selection on Validation data"
      ],
      "metadata": {
        "id": "iPqLXX4Niw2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfEy9kJ999UN",
        "outputId": "8817b09c-e58b-4ee0-e935-a19378b59d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 3 1 3 7 3 7 0 9 0 8 5 9 6 7]\n",
            "[4 5 1 9 9 9 7 8 9 8 0 3 2 3 3]\n",
            "Infrence Time (SVM with saliency):  120.44992922600068\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       plane    0.24311   0.29698   0.26736       862\n",
            "         car    0.19170   0.11253   0.14181       862\n",
            "        bird    0.14654   0.22553   0.17765       807\n",
            "         cat    0.16779   0.28506   0.21124       877\n",
            "        deer    0.22523   0.23952   0.23215       835\n",
            "         dog    0.19468   0.18172   0.18797       886\n",
            "        frog    0.23792   0.15986   0.19123       832\n",
            "       horse    0.15130   0.15385   0.15256       832\n",
            "        ship    0.35368   0.23231   0.28043       848\n",
            "       truck    0.16917   0.10477   0.12940       859\n",
            "\n",
            "    accuracy                        0.19929      8500\n",
            "   macro avg    0.20811   0.19921   0.19718      8500\n",
            "weighted avg    0.20822   0.19929   0.19726      8500\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  66  77  74  73  47  22  72 132  43]\n",
            " [170  97  61  87  44  48  36 133  67 119]\n",
            " [ 61  31 182 177 109  69  82  36  36  24]\n",
            " [ 43  44 145 250  58 134  62  71  24  46]\n",
            " [ 47  15 162 128 200  74  76  96  12  25]\n",
            " [ 42  30 142 263  53 161  48  78  19  50]\n",
            " [ 34  17 182 201 109  82 133  34  10  30]\n",
            " [ 34  24 152 137 128 124  57 128  18  30]\n",
            " [225 102  66  59  46  27  14  37 197  75]\n",
            " [141  80  73 114  68  61  29 161  42  90]]\n"
          ]
        }
      ],
      "source": [
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# make predictions\n",
        "predicted = svm_clf_sal.predict(subset_image_data_val)\n",
        "print(predicted[:15])\n",
        "print(val_labels[:15])\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Infrence Time (SVM with saliency): ', stop-start)\n",
        "\n",
        "# print a classification report (built in to sklearn)\n",
        "svm_metrics = metrics.classification_report(val_labels[:val_size], predicted, digits=5, target_names=classesName)\n",
        "print(\"Classification report: \\n\", svm_metrics)\n",
        "\n",
        "# display confusion matrix\n",
        "cm_svm = confusion_matrix(val_labels[:val_size], predicted)\n",
        "print(f\"Confusion matrix:\\n{cm_svm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the SVM with Saliency Subset Feature Extraction mehtod on the Test Set data"
      ],
      "metadata": {
        "id": "k4Cf2tggRrzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 10000\n",
        "\n",
        "# Saliency Subset Featuer Selection\n",
        "\n",
        "saliencyOutput_test = np.zeros((test_size,32,32,3))\n",
        "saliencyMap_test = np.zeros((test_size,32,32))\n",
        "subset_image_data_test = np.zeros((test_size,n,n,3))\n",
        "\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "for i in range(test_size):\n",
        "  image = test_data[i,:,:,:].reshape(32,32,3)\n",
        "  map, _ = saliency_spectral(image)\n",
        "  saliencyMap_test[i,:,:] = map\n",
        "\n",
        "  ''' uncomment to do saliency subset calc'''\n",
        "  # take nxn subset of data with most saliency\n",
        "  subset_image = maximum_saliency_region(map, n, image)\n",
        "  subset_image_data_test[i, :, :, :] = subset_image\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Saliency Map Forward Pass Time: ', stop-start)\n",
        "\n",
        "subset_image_data_test = subset_image_data_test.reshape(test_size,-1)\n",
        "print(subset_image_data_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Test SVM\n",
        "\n",
        "# start timer\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# make predictions\n",
        "predicted = svm_clf_sal.predict(subset_image_data_test)\n",
        "\n",
        "# stop timer\n",
        "stop = timeit.default_timer()\n",
        "print('Infrence Time (SVM with saliency): ', stop-start)\n",
        "\n",
        "# print a classification report (built in to sklearn)\n",
        "svm_metrics = metrics.classification_report(test_labels[:test_size], predicted, digits=5, target_names=classesName)\n",
        "print(\"Classification report: \\n\", svm_metrics)\n",
        "\n",
        "# display confusion matrix\n",
        "cm_svm = confusion_matrix(test_labels[:test_size], predicted)\n",
        "print(f\"Confusion matrix:\\n{cm_svm}\")\n"
      ],
      "metadata": {
        "id": "7eciHXN7RwXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff830c1e-929f-49b6-c195-bdec6fa9f274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saliency Map Forward Pass Time:  29.830723207996925\n",
            "(10000, 2352)\n",
            "Infrence Time (SVM with saliency):  807.0102195339969\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       plane    0.49954   0.54200   0.51990      1000\n",
            "         car    0.53774   0.57700   0.55668      1000\n",
            "        bird    0.34683   0.39400   0.36891      1000\n",
            "         cat    0.29508   0.32400   0.30887      1000\n",
            "        deer    0.42684   0.42300   0.42491      1000\n",
            "         dog    0.37207   0.38100   0.37648      1000\n",
            "        frog    0.53207   0.44800   0.48643      1000\n",
            "       horse    0.52183   0.47800   0.49896      1000\n",
            "        ship    0.59290   0.56800   0.58018      1000\n",
            "       truck    0.53022   0.46500   0.49547      1000\n",
            "\n",
            "    accuracy                        0.46000     10000\n",
            "   macro avg    0.46551   0.46000   0.46168     10000\n",
            "weighted avg    0.46551   0.46000   0.46168     10000\n",
            "\n",
            "Confusion matrix:\n",
            "[[542  49  73  27  50  24  15  45 125  50]\n",
            " [ 62 577  22  30  24  18  15  22  70 160]\n",
            " [ 82  29 394 109 124  81  78  57  27  19]\n",
            " [ 39  35 109 324  65 225  90  60  19  34]\n",
            " [ 61  10 148  88 423  71  96  66  23  14]\n",
            " [ 21  25 123 212  70 381  44  77  25  22]\n",
            " [ 23  20 120 142 113  73 448  35  14  12]\n",
            " [ 47  34  89  85  78  96  26 478  16  51]\n",
            " [145  90  30  32  27  22  13  23 568  50]\n",
            " [ 63 204  28  49  17  33  17  53  71 465]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BaselineSVM_and_SaliencyMaps",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}